{
  "metadata" : {
    "name" : "Convert ADAM",
    "user_save_timestamp" : "2015-01-02T15:30:31.847Z",
    "auto_save_timestamp" : "2015-01-02T15:30:11.153Z"
  },
  "worksheets" : [ {
    "cells" : [ {
      "cell_type" : "code",
      "input" : ":local-repo /tmp/spark-notebook/repo",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 1,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Check the master name to construct the HDFS and configure Spark"
    }, {
      "cell_type" : "code",
      "input" : "import sys.process._\nval master = (\"ec2-metadata --public-hostname\"!!).drop(\"public-hostname: \".size).mkString.trim",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 3,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "The input VCF file on HDFS and the conversion target"
    }, {
      "cell_type" : "code",
      "input" : "def hu(s:String) = s\"hdfs://$master:9010/temp/$s\"\nval vcfFile = hu(\"ALL.chr1.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf\")\nval outputFile = vcfFile+\".adam\"  ",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Setting SPark with ADAM libs"
    }, {
      "cell_type" : "code",
      "input" : ":dp org.bdgenomics.adam % adam-apis % 0.15.0\n- org.apache.hadoop % hadoop-client %   _\n- org.apache.spark  %     _         %   _\n- org.scala-lang    %     _         %   _\n- org.scoverage     %     _         %   _",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Update Spark configuration to cope with ADAM's needs"
    }, {
      "cell_type" : "code",
      "input" : "reset(lastChanges = _.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n                     .set(\"spark.kryo.registrator\", \"org.bdgenomics.adam.serialization.ADAMKryoRegistrator\")\n                     .set(\"spark.kryoserializer.buffer.mb\", \"4\")\n                     .set(\"spark.kryo.referenceTracking\", \"true\")\n      \t\t\t\t .setMaster(s\"spark://$master:7077\")\n                     .setAppName(\"ADAM 1000genomes\")\n                     .set(\"spark.executor.memory\", \"13g\")\n)",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Imports all Spark and ADAM package and types we'll after."
    }, {
      "cell_type" : "code",
      "input" : "import org.apache.hadoop.fs.{FileSystem, Path}\n\nimport org.bdgenomics.adam.converters.{ VCFLine, VCFLineConverter, VCFLineParser }\nimport org.bdgenomics.formats.avro.{Genotype, FlatGenotype}\nimport org.bdgenomics.adam.models.VariantContext\nimport org.bdgenomics.adam.rdd.ADAMContext._\nimport org.bdgenomics.adam.rdd.variation.VariationContext._\nimport org.bdgenomics.adam.rdd.ADAMContext\n  \nimport org.apache.spark.rdd.RDD",
      "language" : "scala",
      "collapsed" : true,
      "prompt_number" : 2,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Load the input file using the `VariantContext` and convert into ADAM's schema"
    }, {
      "cell_type" : "code",
      "input" : "val variants: RDD[VariantContext] = sparkContext.adamVCFLoad(vcfFile, dict = None)",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Keep only the `Genotype`s out of it"
    }, {
      "cell_type" : "code",
      "input" : "val gts:RDD[Genotype] = variants.flatMap(p => p.genotypes)\n",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Save the genotypes back to HDFS (using avro → parquet serialization)"
    }, {
      "cell_type" : "code",
      "input" : "import org.bdgenomics.adam.rdd.ADAMContext._\ngts.adamParquetSave(outputFile)",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Test the output file in HDFS"
    }, {
      "cell_type" : "code",
      "input" : "val gts2:RDD[Genotype] = sparkContext.adamLoad(outputFile)",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    }, {
      "cell_type" : "markdown",
      "source" : "Real test → counting how many samples we have in the data"
    }, {
      "cell_type" : "code",
      "input" : "val sampleCount = gts2.map(_.getSampleId.toString.hashCode).distinct.count\ns\"#Samples: $sampleCount\"",
      "language" : "scala",
      "collapsed" : true,
      "outputs" : [ ]
    } ]
  } ],
  "nbformat" : 3
}