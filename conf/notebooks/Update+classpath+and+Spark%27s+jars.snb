{
  "metadata" : {
    "name" : "Update classpath and Spark's jars",
    "user_save_timestamp" : 1419202800000,
    "auto_save_timestamp" : 1417561200000
  },
  "worksheets" : [ {
    "cells" : [ {
      "source" : "### Add a remote repo using an `id`, the `name` and its `url`"
    }, {
      "input" : ":remote-repo oss-sonatype % default % https://oss.sonatype.org/content/repositories/releases/",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 10,
      "outputs" : [ ]
    }, {
      "source" : "### Set the local repo (where jars will be added) "
    }, {
      "input" : ":local-repo /tmp/snb/repository",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 11,
      "outputs" : [ ]
    }, {
      "source" : "### Declare some dependencies require for the analysis."
    }, {
      "source" : "* line starting with `+` or nothing are considered as __includes__\n* lines starting with a `-` are considered to be __excluded__ (from all other includes transitives deps)"
    }, {
      "source" : "__`dp` stands for dependencies, hence the spark context will contain all of them (sent to workers)__ "
    }, {
      "input" : ":dp org.bdgenomics.adam % adam-apis % 0.15.0\n- org.apache.hadoop % hadoop-client %   _\n- org.apache.spark  %     _         %   _\n- org.scala-lang    %     _         %   _\n- org.scoverage     %     _         %   _",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 12,
      "outputs" : [ ]
    }, {
      "source" : "### Check the spark context â†’ the configuration's key `spark.jars` contains all dependencies!"
    }, {
      "input" : "sparkContext.getConf.toDebugString",
      "language" : "scala",
      "collapsed" : false,
      "prompt_number" : 13,
      "outputs" : [ ]
    } ]
  } ],
  "nbformat" : 3
}